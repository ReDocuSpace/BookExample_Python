{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시작\n",
      "20\n",
      "20\n",
      "20\n",
      "40\n",
      "20\n",
      "POWER ENGLISH(EBS 방송교재 2023년 12월) 크리스틴 조 EBS한국교육방송공사 2023.11.27 6,400\n",
      "60\n",
      "20\n",
      "이지 라이팅(Easy Writing)(EBS 방송교재 2023년 12월) 마스터유진 EBS한국교육방송공사 2023.11.27 6,400\n",
      "80\n",
      "20\n",
      "EASY ENGLISH(EBS 방송교재 2023년 12월) 이보영 EBS한국교육방송공사 2023.11.27 6,400\n",
      "100\n",
      "20\n",
      "진짜 미국 영어(EBS 방송교재 2023년 12월) 김교포 EBS한국교육방송공사 2023.11.27 6,400\n",
      "120\n",
      "120\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'best_seller.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32md:\\BookExample_Python\\Lecture02\\Tranning\\2023_11_30.ipynb Cell 1\u001b[0m line \u001b[0;36m9\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/BookExample_Python/Lecture02/Tranning/2023_11_30.ipynb#W0sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/BookExample_Python/Lecture02/Tranning/2023_11_30.ipynb#W0sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m news_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(best_seller_list)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/BookExample_Python/Lecture02/Tranning/2023_11_30.ipynb#W0sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m news_df\u001b[39m.\u001b[39;49mto_csv(\u001b[39m'\u001b[39;49m\u001b[39mbest_seller.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/BookExample_Python/Lecture02/Tranning/2023_11_30.ipynb#W0sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m news_df\n",
      "File \u001b[1;32mc:\\Users\\GJ\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3761\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m   3763\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3764\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[0;32m   3765\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3769\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m   3770\u001b[0m )\n\u001b[1;32m-> 3772\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[0;32m   3773\u001b[0m     path_or_buf,\n\u001b[0;32m   3774\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[0;32m   3775\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[0;32m   3776\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   3777\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   3778\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m   3779\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[0;32m   3780\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   3781\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   3782\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m   3783\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   3784\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[0;32m   3785\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[0;32m   3786\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[0;32m   3787\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[0;32m   3788\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   3789\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\GJ\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1165\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1168\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1169\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1184\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[0;32m   1185\u001b[0m )\n\u001b[1;32m-> 1186\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1189\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\GJ\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:240\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    241\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[0;32m    242\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    243\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    244\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[0;32m    245\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[0;32m    246\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[0;32m    247\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[0;32m    248\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[0;32m    250\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m    251\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[0;32m    257\u001b[0m     )\n\u001b[0;32m    259\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\GJ\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39mioargs\u001b[39m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[39m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'best_seller.csv'"
     ]
    }
   ],
   "source": [
    "# 교보문고\n",
    "# 일간 베스트셀러 목록 100개 출력하기\n",
    "# => 제목, 저자, 출판사, 출판일, 가격, 서머리\n",
    "# csv file로 저장하기\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "url = 'https://www.kyobobook.co.kr/'\n",
    "\n",
    "# 크롬드라이버 열기\n",
    "driver = webdriver.Chrome()\n",
    "# url 열기\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "elem = driver.find_element(By.LINK_TEXT,'베스트')\n",
    "elem.click()\n",
    "\n",
    "\n",
    "print(\"시작\")\n",
    "\n",
    "best_seller_list = []\n",
    "\n",
    "count = 1\n",
    "\n",
    "while True:\n",
    "\n",
    "    time.sleep(2)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    print(len(soup.select('.prod_list > li.prod_item')))\n",
    "    \n",
    "    for item in soup.select('.prod_list > li.prod_item'):\n",
    "        try:\n",
    "            #제목\n",
    "            name = item.select('a.prod_info')[0].text.strip()\n",
    "            #저자\n",
    "            author = item.select('span.prod_author')[0].text.strip().split('·')[0].strip()\n",
    "            #출판사\n",
    "            company = item.select('span.prod_author')[0].text.strip().split('·')[1].strip()\n",
    "            #출판일\n",
    "            date = item.select('span.date')[0].text.split('·')[1].strip()\n",
    "            #가격\n",
    "            price = item.select('span.val')[0].text.strip()\n",
    "            #서머리\n",
    "            summary = item.select('p.prod_introduction')[0].text.strip()\n",
    "            \n",
    "            best_seller_list.append({\n",
    "                \"name\" : name,\n",
    "                \"author\" : author,\n",
    "                \"company\" : company,\n",
    "                \"date\" : date,\n",
    "                \"price\" : price,\n",
    "                \"summary\" : summary,\n",
    "            })\n",
    "        except:\n",
    "            print(name,author,company,date,price)\n",
    "            # summary가 없을 경우 빈칸으로 추가\n",
    "            best_seller_list.append({\n",
    "                \"name\" : name,\n",
    "                \"author\" : author,\n",
    "                \"company\" : company,\n",
    "                \"date\" : date,\n",
    "                \"price\" : price,\n",
    "                \"summary\" : \"\",\n",
    "            })\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    print(len(best_seller_list))\n",
    "    if len(best_seller_list) > 100:\n",
    "        break\n",
    "    if count > 7:\n",
    "        break\n",
    "     \n",
    "    elem = driver.find_element(By.LINK_TEXT,f'{count}')\n",
    "    elem.click()\n",
    "    \n",
    "print(len(best_seller_list))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "news_df = pd.DataFrame(best_seller_list)\n",
    "\n",
    "news_df.to_csv('best_seller.csv')\n",
    "        \n",
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(soup.select('.prod_list > li.prod_item'))\n",
    "#len(soup.select('.prod_list > li'))\n",
    "\n",
    "for item in soup.select('.prod_list > li.prod_item'):\n",
    "    #제목\n",
    "    name = item.select('a.prod_info')[0].text.strip()\n",
    "    #저자\n",
    "    author = item.select('span.prod_author')[0].text.strip().split('·')[0].strip()\n",
    "    #출판사\n",
    "    company = item.select('span.prod_author')[0].text.strip().split('·')[1].strip()\n",
    "    #출판일\n",
    "    date = item.select('span.date')[0].text.split('·')[1].strip()\n",
    "    #가격\n",
    "    price = item.select('span.val')[0].text.strip()\n",
    "    #서머리\n",
    "    summary = item.select('p.prod_introduction')[0].text.strip()\n",
    "    \n",
    "    print(name)\n",
    "    print(author)\n",
    "    print(company)\n",
    "    print(date)\n",
    "    print(price)\n",
    "    print(summary)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "\n",
    "elem = driver.find_element(By.CSS_SELECTOR, '#welcome_header_wrap > div.header_inner > nav > ul.gnb_list > li:nth-child(3) > a')\n",
    "elem.click()\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "lis = soup.select('#tabRoot > div.view_type_list.switch_prod_wrap > ol > li')\n",
    "len(lis)\n",
    "\n",
    "title = lis[0].select('div.prod_area.horizontal > div.prod_info_box > a > span')[0].text\n",
    "date = lis[0].select('div.prod_area.horizontal > div.prod_info_box > span > .date')[0].text.replace('·', '').strip()\n",
    "author = lis[0].select('div.prod_area.horizontal > div.prod_info_box > span.prod_author')[0].text.replace(date, '').replace('·', '').split()[0]\n",
    "press = lis[0].select('div.prod_area.horizontal > div.prod_info_box > span.prod_author')[0].text.replace(date, '').replace('·', '').split()[1]\n",
    "\n",
    "for li in lis:\n",
    "    title = li.select('div.prod_area.horizontal > div.prod_info_box > a > span')[0].text\n",
    "    date = li.select('div.prod_area.horizontal > div.prod_info_box > span > .date')[0].text.replace('·', '').strip()\n",
    "    author = li.select('div.prod_area.horizontal > div.prod_info_box > span.prod_author')[0].text.replace(date, '').replace('·', '').split()[0]\n",
    "    press = li.select('div.prod_area.horizontal > div.prod_info_box > span.prod_author')[0].text.replace(date, '').replace('·', '').split()[1]\n",
    "    \n",
    "    print(title)\n",
    "    print(author)\n",
    "    print(date)\n",
    "    print(press)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for li in lis:\n",
    "    title = li.select('div.prod_area.horizontal > div.prod_info_box > a > span')[0].text\n",
    "    date = li.select('div.prod_area.horizontal > div.prod_info_box > span > .date')[0].text.replace('·', '').strip()\n",
    "    author = li.select('div.prod_area.horizontal > div.prod_info_box > span.prod_author')[0].text.replace(date, '').replace('·', '').split()[0]\n",
    "    press = li.select('div.prod_area.horizontal > div.prod_info_box > span.prod_author')[0].text.replace(date, '').replace('·', '').split()[1]\n",
    "    \n",
    "    print(title)\n",
    "    print(author)\n",
    "    print(date)\n",
    "    print(press)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SCROLL_PAUSE_TIME = 2\n",
    "\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "#while True: \n",
    "    driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "    \n",
    "    new_height = driver.execute_script('return document.body.scrollHeight')\n",
    "    if new_height == last_height:\n",
    "        try:\n",
    "            time.sleep(SCROLL_PAUSE_TIME)\n",
    "            driver.find_element(By.CSS_SELECTOR, \"input.mye4qd\").click()\n",
    "        except:\n",
    "            break\n",
    "    last_height = new_height\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    #try:\n",
    "    #    elem = driver.find_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "url = 'https://www.google.com/'\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "\n",
    "select = '고양이'\n",
    "\n",
    "elem = driver.find_element(By.CSS_SELECTOR, '#APjFqb')\n",
    "\n",
    "elem.send_keys(select)\n",
    "elem.send_keys(Keys.RETURN)\n",
    "\n",
    "elem = driver.find_element(By.CSS_SELECTOR, '#hdtb-msb > div:nth-child(1) > div > div:nth-child(2) > a')\n",
    "elem = driver.find_element(By.LINK_TEXT, '이미지')\n",
    "elem.click()\n",
    "\n",
    "# 스크롤을 끝까지 내리는 코드\n",
    "\n",
    "SCROLL_PAUSE_TIME = 2\n",
    "\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "while True: \n",
    "    driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "    \n",
    "    new_height = driver.execute_script('return document.body.scrollHeight')\n",
    "    if new_height == last_height:\n",
    "        try:\n",
    "            time.sleep(SCROLL_PAUSE_TIME)\n",
    "            driver.find_element(By.CSS_SELECTOR, \"input.mye4qd\").click()\n",
    "        except:\n",
    "            break\n",
    "    last_height = new_height\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    try:\n",
    "        elem = driver.find_element(By.CSS_SELECTOR, '#islmp > div > div > div > div > div.C5Hr4 > div.K414Oe > div.FAGjZe > input')\n",
    "        elem.click()\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "url = 'https://www.google.com/'\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "time.sleep(1)\n",
    "\n",
    "elem = driver.find_element(By.CSS_SELECTOR, '#APjFqb')\n",
    "sk = \"할로\"\n",
    "elem.send_keys(sk)\n",
    "elem.send_keys(Keys.RETURN)\n",
    "time.sleep(1)\n",
    "elem = driver.find_element(By.LINK_TEXT,'이미지')\n",
    "#elem = driver.find_element(By.CSS_SELECTOR, '#hdtb-msb > div:nth-child(1) > div > div:nth-child(2) > a')\n",
    "elem.click()\n",
    "time.sleep(1)\n",
    "SCROLL_PAUSE_TIME = 2\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "#while True:\n",
    "#    driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "#    time.sleep(SCROLL_PAUSE_TIME)\n",
    "#    new_height = driver.execute_script('return document.body.scrollHeight')\n",
    "#    if new_height == last_height:\n",
    "#        try:\n",
    "#            time.sleep(SCROLL_PAUSE_TIME)\n",
    "#            driver.find_element(By.CSS_SELECTOR, \"input.mye4qd\").click()\n",
    "#        except:\n",
    "#            break\n",
    "#    last_height = new_height\n",
    "#    time.sleep(1)\n",
    "#    try:\n",
    "#        elem = driver.find_element(By.CSS_SELECTOR, '#islmp > div > div > div > div > div.C5Hr4 > div.K414Oe > div.FAGjZe > input')\n",
    "#        elem.click()\n",
    "#    except:\n",
    "#        pass\n",
    "############################################\n",
    "\n",
    "path = '#islrg > div.islrc > div > a.FRuiCf.islib.nfEiy > div.fR600b.islir > img'\n",
    "\n",
    "elems = driver.find_elements(By.CSS_SELECTOR, path)\n",
    "\n",
    "\n",
    "for i, elem in enumerate(elems):\n",
    "    try:\n",
    "        elem.click()\n",
    "        time.sleep(1)\n",
    "        elem = driver.find_element(By.XPATH, '//*[@id=\"Sva75c\"]/div[2]/div[2]/div[2]/div[2]/c-wiz/div/div/div/div/div[3]/div[1]/a/img[1]')\n",
    "        img_url = elem.get_attribute('src')\n",
    "        print(img_url)\n",
    "        urlretrieve(img_url, \"./test_image/image_{}\".format(i))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import sys\n",
    "import os\n",
    "\n",
    "elems = driver.find_elements(By.CSS_SELECTOR,'#islrg > div.islrc > div > a.FRuiCf.islib.nfEiy > div.fR600b.islir > img')\n",
    "len(elems)\n",
    "\n",
    "current_path = globals()['_dh'][0]\n",
    "folderName = 'Test_Image'\n",
    "\n",
    "for i, item in enumerate(elems):\n",
    "    try:\n",
    "        item.click()\n",
    "        time.sleep(1)\n",
    "        elem = driver.find_element(By.XPATH,'//*[@id=\"Sva75c\"]/div[2]/div[2]/div[2]/div[2]/c-wiz/div/div/div/div/div[3]/div[1]/a/img[1]')\n",
    "\n",
    "        img_url = elem.get_attribute('src')\n",
    "        print(img_url)\n",
    "        \n",
    "        image_path = os.path.join(current_path,folderName)\n",
    "        \n",
    "        if os.path.exists(folderName) == True: # 파일이랑 폴더 경로\n",
    "            os.mkdir(folderName) # 폴더 생성하기\n",
    "            \n",
    "        urlretrieve(img_url, os.path.join(image_path,'go_img{}.jpg'.format(i)))\n",
    "    except:\n",
    "        print(\"error\")\n",
    "        print(item)\n",
    "        pass\n",
    "    \n",
    "    #urlretrieve(img_url, './google_image/go_img{}.jpg'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_path = globals()['_dh'][0]\n",
    "\n",
    "print(current_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
