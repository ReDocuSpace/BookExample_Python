{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교보문고\n",
    "# 일간 베스트셀러 목록 100개 출력하기\n",
    "# => 제목, 저자, 출판사, 출판일, 가격, 서머리\n",
    "# csv file로 저장하기\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "best_li = []\n",
    "url = 'https://www.kyobobook.co.kr/'\n",
    "\n",
    "# 크롬드라이버 열기\n",
    "driver = webdriver.Chrome()\n",
    "# url 열기\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "elem = driver.find_element(By.LINK_TEXT,'베스트')\n",
    "elem.click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "count = 1\n",
    "while count < 2:\n",
    "    if len(best_li) > 150:\n",
    "        break\n",
    "\n",
    "    # 대기시간\n",
    "    time.sleep(2)\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    for item in soup.select('.prod_list > li'):\n",
    "        try:\n",
    "            #제목\n",
    "            name = item.select('.prod_name')[0].text.strip()\n",
    "            #저자\n",
    "            author = item.select('.prod_author')[0].text.strip().split('·')[0].strip()\n",
    "            #출판사\n",
    "            company = item.select('.prod_author')[0].text.strip().split('·')[1].strip()\n",
    "            #출판일\n",
    "            date = item.select('.date')[0].text.split('·')[1].strip()\n",
    "            #가격\n",
    "            price = item.select('.price')[0].text.strip()\n",
    "            #서머리\n",
    "            summary = item.select('.prod_introduction')[0].text.strip()\n",
    "    \n",
    "            best_li.append({\"제목\" : name , \"저자\" : author, \"출판사\" : company , \"출판일\" : date, \"가격\" : price, \"서머리\" : summary})\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    count += 1\n",
    "\n",
    "    elem = driver.find_element(By.LINK_TEXT,f'{str(count)}')\n",
    "    elem.click()\n",
    "    \n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "news_df = pd.DataFrame(best_li)\n",
    "\n",
    "news_df.to_csv('best_seller.csv')\n",
    "        \n",
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "\n",
    "elem = driver.find_element(By.CSS_SELECTOR, '#welcome_header_wrap > div.header_inner > nav > ul.gnb_list > li:nth-child(3) > a')\n",
    "elem.click()\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "lis = soup.select('#tabRoot > div.view_type_list.switch_prod_wrap > ol > li')\n",
    "len(lis)\n",
    "\n",
    "title = lis[0].select('div.prod_area.horizontal > div.prod_info_box > a > span')[0].text\n",
    "date = lis[0].select('div.prod_area.horizontal > div.prod_info_box > span > .date')[0].text.replace('·', '').strip()\n",
    "author = lis[0].select('div.prod_area.horizontal > div.prod_info_box > span.prod_author')[0].text.replace(date, '').replace('·', '').split()[0]\n",
    "press = lis[0].select('div.prod_area.horizontal > div.prod_info_box > span.prod_author')[0].text.replace(date, '').replace('·', '').split()[1]\n",
    "\n",
    "for li in lis:\n",
    "    title = li.select('div.prod_area.horizontal > div.prod_info_box > a > span')[0].text\n",
    "    date = li.select('div.prod_area.horizontal > div.prod_info_box > span > .date')[0].text.replace('·', '').strip()\n",
    "    author = li.select('div.prod_area.horizontal > div.prod_info_box > span.prod_author')[0].text.replace(date, '').replace('·', '').split()[0]\n",
    "    press = li.select('div.prod_area.horizontal > div.prod_info_box > span.prod_author')[0].text.replace(date, '').replace('·', '').split()[1]\n",
    "    \n",
    "    print(title)\n",
    "    print(author)\n",
    "    print(date)\n",
    "    print(press)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for li in lis:\n",
    "    title = li.select('div.prod_area.horizontal > div.prod_info_box > a > span')[0].text\n",
    "    date = li.select('div.prod_area.horizontal > div.prod_info_box > span > .date')[0].text.replace('·', '').strip()\n",
    "    author = li.select('div.prod_area.horizontal > div.prod_info_box > span.prod_author')[0].text.replace(date, '').replace('·', '').split()[0]\n",
    "    press = li.select('div.prod_area.horizontal > div.prod_info_box > span.prod_author')[0].text.replace(date, '').replace('·', '').split()[1]\n",
    "    \n",
    "    print(title)\n",
    "    print(author)\n",
    "    print(date)\n",
    "    print(press)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = \"#comic > img\"\n",
    "# 경로 가져오기\n",
    "tag = soup.select(path)\n",
    "img_url = 'https:' + tag[0]['src']\n",
    "\n",
    "# 이진 파일 내용 가져오기\n",
    "res = requests.get(img_url)\n",
    "\n",
    "# 파일 입출력 가져오기\n",
    "#f = open('catoon.jpg','wb')\n",
    "#f.write(res.content)\n",
    "#f.close()\n",
    "\n",
    "# 파일 입출력 가져오기 [안전]\n",
    "f = open('catoon_123.jpg','wb')\n",
    "# 100 바이트씩 읽어서 저장\n",
    "for chunk in res.iter_content(100):\n",
    "    f.write(chunk)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SCROLL_PAUSE_TIME = 2\n",
    "\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "#while True: \n",
    "    driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "    \n",
    "    new_height = driver.execute_script('return document.body.scrollHeight')\n",
    "    if new_height == last_height:\n",
    "        try:\n",
    "            time.sleep(SCROLL_PAUSE_TIME)\n",
    "            driver.find_element(By.CSS_SELECTOR, \"input.mye4qd\").click()\n",
    "        except:\n",
    "            break\n",
    "    last_height = new_height\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    #try:\n",
    "    #    elem = driver.find_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "url = 'https://www.google.com/'\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "\n",
    "select = '고양이'\n",
    "\n",
    "elem = driver.find_element(By.CSS_SELECTOR, '#APjFqb')\n",
    "\n",
    "elem.send_keys(select)\n",
    "elem.send_keys(Keys.RETURN)\n",
    "\n",
    "elem = driver.find_element(By.CSS_SELECTOR, '#hdtb-msb > div:nth-child(1) > div > div:nth-child(2) > a')\n",
    "elem.click()\n",
    "\n",
    "# 스크롤을 끝까지 내리는 코드\n",
    "\n",
    "SCROLL_PAUSE_TIME = 2\n",
    "\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "while True: \n",
    "    driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "    \n",
    "    new_height = driver.execute_script('return document.body.scrollHeight')\n",
    "    if new_height == last_height:\n",
    "        try:\n",
    "            time.sleep(SCROLL_PAUSE_TIME)\n",
    "            driver.find_element(By.CSS_SELECTOR, \"input.mye4qd\").click()\n",
    "        except:\n",
    "            break\n",
    "    last_height = new_height\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    try:\n",
    "        elem = driver.find_element(By.CSS_SELECTOR, '#islmp > div > div > div > div > div.C5Hr4 > div.K414Oe > div.FAGjZe > input')\n",
    "        elem.click()\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\BookExample_Python\\Lecture02\\Tranning\\2023_11_30.ipynb Cell 9\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/BookExample_Python/Lecture02/Tranning/2023_11_30.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m elems \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39mfind_elements(By\u001b[39m.\u001b[39mCSS_SELECTOR,\u001b[39m'\u001b[39m\u001b[39m#islrg > div.islrc > div > div > a.FRuiCf.islib.nfEiy > div.fR600b.islir > img\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/BookExample_Python/Lecture02/Tranning/2023_11_30.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mlen\u001b[39m(elems)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/BookExample_Python/Lecture02/Tranning/2023_11_30.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m current_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(\u001b[39m__file__\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/BookExample_Python/Lecture02/Tranning/2023_11_30.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, item \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(elems):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/BookExample_Python/Lecture02/Tranning/2023_11_30.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import sys\n",
    "import os\n",
    "\n",
    "elems = driver.find_elements(By.CSS_SELECTOR,'#islrg > div.islrc > div > div > a.FRuiCf.islib.nfEiy > div.fR600b.islir > img')\n",
    "len(elems)\n",
    "\n",
    "current_path = os.path.dirname(__file__)\n",
    "\n",
    "for i, item in enumerate(elems):\n",
    "    try:\n",
    "        item.click()\n",
    "        time.sleep(1)\n",
    "        elem = driver.find_element(By.XPATH,'//*[@id=\"Sva75c\"]/div[2]/div[2]/div[2]/div[2]/c-wiz/div/div/div/div/div[3]/div[1]/a/img[1]')\n",
    "    \n",
    "        img_url = elem.get_attribute('src')\n",
    "        print(img_url)\n",
    "        \n",
    "        image_path = os.path.join(current_path,'Test_Image')\n",
    "        \n",
    "        urlretrieve(img_url, os.path.join(image_path,'go_img{}.jpg'.format(i)))\n",
    "    except:\n",
    "        print(\"error\")\n",
    "        print(item)\n",
    "        pass\n",
    "    \n",
    "    #urlretrieve(img_url, './google_image/go_img{}.jpg'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
